1.  Login to the machine as a non-super user

2.  Ensure, your user is in the sodoers file, so that you can execute commands as sudo

3.  Execute the following to update the system
        sudo apt update

4.  If you wish to upgrade the system, execute the following
        sudo apt upgrade -y

5.  Since Apache-Spark is a java based application, ensure you have JDK installed.
    Execute the following to check, if java is already installed on the OS
        java --version

        Output:
        devops@ubuntu:/$ java --version
        openjdk 11.0.17 2022-10-18
        OpenJDK Runtime Environment (build 11.0.17+8-post-Ubuntu-1ubuntu222.04)
        OpenJDK 64-Bit Server VM (build 11.0.17+8-post-Ubuntu-1ubuntu222.04, mixed mode, sharing)
        devops@ubuntu:/$

6.  If Java is not installed, execute the following to install it on Ubuntu
        sudo apt install default-jdk

7.  The current working directory is 'your home' directory on the Server
        /home/devops/
    Since you logged in, you have not changed in to another directory.

8.  Execute the following to download the tarball from Apache Spark's website
        wget https://archive.apache.org/dist/spark/spark-3.0.3/spark-3.0.3-bin-hadoop2.7.tgz

9.  Once the tar ball is downloaded successfully, untar it, by executing the following command
        tar xvf spark-3.0.3-bin-hadoop2.7.tgz

10. Move the expanded tar ball to /opt/, by executing the following command
        sudo mv ~/spark-3.0.3-bin-hadoop2.7/ /opt/

11. Rename the 'spark-3.0.3-bin-hadoop2.7' directory to 'spark' under /opt/, by executing following command
        sudo mv /opt/spark-3.0.3-bin-hadoop2.7 /opt/spark

12. 